{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "light-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cardiac-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keluhan</th>\n",
       "      <th>bagian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya sudah membayar EPRT tapi status di igraci...</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tolong adakan EPRT online agar mempermudah dal...</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saya sudah mencoba membayar bpp melalui atm ma...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selamat siang, saya mau menanyakan bagaimana p...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koleksi buku seni yang sangat sedikit tolong d...</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kurangnya stop kontak untuk pengunjung dan sto...</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saya mengalami kesulitan dalam membayar Eprt d...</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keluhan        bagian\n",
       "0  Saya sudah membayar EPRT tapi status di igraci...  PUSAT BAHASA\n",
       "1  tolong adakan EPRT online agar mempermudah dal...  PUSAT BAHASA\n",
       "2  Saya sudah mencoba membayar bpp melalui atm ma...     AKUNTANSI\n",
       "3  Selamat siang, saya mau menanyakan bagaimana p...     AKUNTANSI\n",
       "4  Koleksi buku seni yang sangat sedikit tolong d...  OPEN LIBRARY\n",
       "5  Kurangnya stop kontak untuk pengunjung dan sto...  OPEN LIBRARY\n",
       "6  saya mengalami kesulitan dalam membayar Eprt d...  PUSAT BAHASA"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data traning\n",
    "data_path = 'C:/Users/ASUS/TA01/00_data/data_perhitunganbab3.csv'\n",
    "data = pd.read_csv(data_path, sep=';')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "crazy-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessing:\n",
    "    def __init__(self, text=\"test\"):\n",
    "        self.text = text\n",
    "\n",
    "    def lowercase(self):\n",
    "        \"\"\"Convert to lowercase\"\"\"\n",
    "        self.text = str(self.text).lower()\n",
    "        self.text = self.text.strip()\n",
    "        return self\n",
    "\n",
    "    def remove_url(self):\n",
    "        \"\"\"Remove URL (http/https/www) or custom URL\"\"\"\n",
    "        self.text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_email(self):\n",
    "        \"\"\"Remove email\"\"\"\n",
    "        self.text = re.sub(\"\\S*@\\S*\\s?\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_between_square_brackets(self):\n",
    "        \"\"\"Remove string beetwen square brackets []\"\"\"\n",
    "        self.text = re.sub(\"\\[[^]]*\\]\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        \"\"\"Remove numbers\"\"\"\n",
    "        self.text = re.sub(\"[-+]?[0-9]+\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        \"\"\"Remove punctuation\"\"\"\n",
    "        self.text = re.sub(r\"[^\\w\\s]\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def normalize_word(self):\n",
    "        \"\"\"Normalize slang world\"\"\"\n",
    "        normal_word_path = pd.read_csv(\"C:/Users/ASUS/TA01/00_data/key_norm.csv\")\n",
    "\n",
    "        self.text = \" \".join(\n",
    "            [\n",
    "                normal_word_path[normal_word_path[\"singkat\"] == word][\"hasil\"].values[0]\n",
    "                if (normal_word_path[\"singkat\"] == word).any()\n",
    "                else word\n",
    "                for word in self.text.split()\n",
    "            ]\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def stemming(self):\n",
    "        \"\"\"Stemming for Bahasa with Sastrawi\"\"\"\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        self.text = stemmer.stem(self.text)\n",
    "        return self\n",
    "\n",
    "    def tokenize(self):\n",
    "        \"\"\"Tokenize words\"\"\"\n",
    "        self.words = nltk.word_tokenize(self.text)\n",
    "        return self\n",
    "\n",
    "    def stopwords_removal(self):\n",
    "        \"\"\"Stopword removal\"\"\"\n",
    "        stopword = stopwords.words(\"indonesian\")\n",
    "        more_stopword = [\n",
    "            \"assalamualaikum\", \"wr\", \"wb\", \"pak\",\n",
    "            \"bu\", \"selamat\", \"siang\", \"pagi\",\n",
    "            \"sore\", \"malam\", \"saya\",\n",
    "            \"terimakasih\", \"terima\",\n",
    "            \"kasih\", \"kepada\", \"bpk\",\n",
    "            \"ibu\", \"mohon\", \"tolong\",\n",
    "            \"maaf\", \"dear\", \"wassalamualaikum\",\n",
    "            \"regards\", \"nbsp\", \"amp\", \"lg\", \"lgi\", \"kak\",\n",
    "            \"bapakibu\",\"bapak\", \"admin\",\"pakbu\",\"bupak\",\"wrwb\",\"ya\",\"min\" ]  # add more stopword to default corpus\n",
    "        stop_factory = stopword + more_stopword\n",
    "        stop_factory.remove('tak')\n",
    "        stop_factory.remove('akhir')\n",
    "        \n",
    "        clean_words = []\n",
    "        for word in self.words:\n",
    "            if word not in stop_factory:\n",
    "                clean_words.append(word)\n",
    "        self.words = clean_words  \n",
    "        return self\n",
    "\n",
    "    def join_words(self):\n",
    "        \"\"\"Join all words\"\"\"\n",
    "        self.words = \" \".join(self.words)\n",
    "        return self\n",
    "    \n",
    "    def do_all(self, text):\n",
    "        \"\"\"Do all text preprocessing process\"\"\" \n",
    "        self.text = text\n",
    "        self = self.lowercase()\n",
    "        self = self.remove_url()\n",
    "        self = self.remove_email()\n",
    "        self = self.remove_between_square_brackets()\n",
    "        self = self.remove_numbers()\n",
    "        self = self.remove_punctuation()\n",
    "        self = self.normalize_word()\n",
    "        self = self.stemming()\n",
    "        self = self.tokenize()\n",
    "        self = self.stopwords_removal()\n",
    "        self = self.join_words()\n",
    "        return self.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "modern-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing() # load module text preprocessing\n",
    "\n",
    "data['clean_keluhan'] = data['keluhan'].apply(tp.do_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "approximate-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_keluhan</th>\n",
       "      <th>bagian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayar eprt status igracias update bantu</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adakan eprt online mudah proses ketes eprt</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coba bayar bpp atm teller ganggu rek telkomnya...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perihal alih uang bpp semester semester</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koleksi buku seni</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop kontak unjung stop kontak fungsi</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alami sulit bayar eprt mbanking mandiri bantu</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_keluhan        bagian\n",
       "0            bayar eprt status igracias update bantu  PUSAT BAHASA\n",
       "1         adakan eprt online mudah proses ketes eprt  PUSAT BAHASA\n",
       "2  coba bayar bpp atm teller ganggu rek telkomnya...     AKUNTANSI\n",
       "3            perihal alih uang bpp semester semester     AKUNTANSI\n",
       "4                                  koleksi buku seni  OPEN LIBRARY\n",
       "5              stop kontak unjung stop kontak fungsi  OPEN LIBRARY\n",
       "6      alami sulit bayar eprt mbanking mandiri bantu  PUSAT BAHASA"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['clean_keluhan', 'bagian']\n",
    "data = data[columns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "victorian-compound",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_keluhan</th>\n",
       "      <th>bagian</th>\n",
       "      <th>bagian_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayar eprt status igracias update bantu</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adakan eprt online mudah proses ketes eprt</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coba bayar bpp atm teller ganggu rek telkomnya...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perihal alih uang bpp semester semester</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koleksi buku seni</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop kontak unjung stop kontak fungsi</td>\n",
       "      <td>OPEN LIBRARY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alami sulit bayar eprt mbanking mandiri bantu</td>\n",
       "      <td>PUSAT BAHASA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_keluhan        bagian  \\\n",
       "0            bayar eprt status igracias update bantu  PUSAT BAHASA   \n",
       "1         adakan eprt online mudah proses ketes eprt  PUSAT BAHASA   \n",
       "2  coba bayar bpp atm teller ganggu rek telkomnya...     AKUNTANSI   \n",
       "3            perihal alih uang bpp semester semester     AKUNTANSI   \n",
       "4                                  koleksi buku seni  OPEN LIBRARY   \n",
       "5              stop kontak unjung stop kontak fungsi  OPEN LIBRARY   \n",
       "6      alami sulit bayar eprt mbanking mandiri bantu  PUSAT BAHASA   \n",
       "\n",
       "   bagian_label  \n",
       "0             2  \n",
       "1             2  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "5             1  \n",
       "6             2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bagian_label'] = LabelEncoder().fit_transform(data['bagian']) #memberi label pada setiap bagian\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "killing-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test data\n",
    "x_train=data['clean_keluhan']\n",
    "y_train=data['bagian_label']                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endangered-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text representation: TF-IDF\n",
    "# TF-IDF parameter\n",
    "ngram_range = (1,1) #untuk menghitung tfidf unigram dan bigram\n",
    "min_df = 1\n",
    "max_df = 1.0 #mindf dan maxdf untuk memberi batasan minimum dan maksimum ngram yang akan digunakan pada fungsi TfidfVectorizer\n",
    "max_features = 11 #untuk mendapatkan 1000 top term dengan term frequency terbesar\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True) #membuat objek tfidfvectorizer ke variabel tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offshore-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.637414434663118\n",
      "  (0, 3)\t0.5448407283248461\n",
      "  (0, 1)\t0.5448407283248461\n",
      "  (1, 3)\t1.0\n",
      "  (2, 5)\t0.34622197445231473\n",
      "  (2, 6)\t0.41709175289853345\n",
      "  (2, 7)\t0.7061977254549573\n",
      "  (2, 2)\t0.34622197445231473\n",
      "  (2, 1)\t0.2959390664291466\n",
      "  (3, 8)\t0.8978972949445114\n",
      "  (3, 2)\t0.4402050064814449\n",
      "  (5, 4)\t0.7071067811865475\n",
      "  (5, 9)\t0.7071067811865475\n",
      "  (6, 10)\t0.543530401770053\n",
      "  (6, 5)\t0.45117691147795724\n",
      "  (6, 0)\t0.45117691147795724\n",
      "  (6, 3)\t0.38565106731999843\n",
      "  (6, 1)\t0.38565106731999843\n"
     ]
    }
   ],
   "source": [
    "features_train = tfidf.fit_transform(x_train) #memanggil method fit.transform dari objek tfidf pada x_train\n",
    "labels_train = y_train\n",
    "print(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bantu',\n",
       " 'bayar',\n",
       " 'bpp',\n",
       " 'eprt',\n",
       " 'kontak',\n",
       " 'mandiri',\n",
       " 'pakai',\n",
       " 'rek',\n",
       " 'semester',\n",
       " 'stop',\n",
       " 'sulit']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confident-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bantu</th>\n",
       "      <td>0.637414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bayar</th>\n",
       "      <td>0.544841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpp</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346222</td>\n",
       "      <td>0.440205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eprt</th>\n",
       "      <td>0.544841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kontak</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandiri</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pakai</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rek</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                D0   D1        D2        D3   D4        D5        D6\n",
       "bantu     0.637414  0.0  0.000000  0.000000  0.0  0.000000  0.451177\n",
       "bayar     0.544841  0.0  0.295939  0.000000  0.0  0.000000  0.385651\n",
       "bpp       0.000000  0.0  0.346222  0.440205  0.0  0.000000  0.000000\n",
       "eprt      0.544841  1.0  0.000000  0.000000  0.0  0.000000  0.385651\n",
       "kontak    0.000000  0.0  0.000000  0.000000  0.0  0.707107  0.000000\n",
       "mandiri   0.000000  0.0  0.346222  0.000000  0.0  0.000000  0.451177\n",
       "pakai     0.000000  0.0  0.417092  0.000000  0.0  0.000000  0.000000\n",
       "rek       0.000000  0.0  0.706198  0.000000  0.0  0.000000  0.000000\n",
       "semester  0.000000  0.0  0.000000  0.897897  0.0  0.000000  0.000000\n",
       "stop      0.000000  0.0  0.000000  0.000000  0.0  0.707107  0.000000\n",
       "sulit     0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.543530"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(features_train.todense().T,\n",
    "                  index=tfidf.get_feature_names(),\n",
    "                  columns=[f'D{i+0}' for i in range(len(x_train))])\n",
    "\n",
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regular-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid # nearest centroid classifier\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "documented-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc = NearestCentroid()\n",
    "ncc.fit(features_train, labels_train) # training\n",
    "ncc_predict = ncc.predict(features_train) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valuable-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, ncc.predict(features_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "plastic-boating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         7\n",
      "   macro avg       1.00      1.00      1.00         7\n",
      "weighted avg       1.00      1.00      1.00         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_train, ncc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developmental-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "category_codes = {\n",
    "    'Akuntansi': 0,\n",
    "    'Oplib': 1,\n",
    "    'Pusat Bahasa': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "korean-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing() # load module text preprocessing\n",
    "\n",
    "def create_features(text):\n",
    "    df = pd.DataFrame(columns=['keluhan'])\n",
    "    df.loc[0] = text\n",
    "    df['keluhan'] = df['keluhan'].apply(tp.do_all)\n",
    "\n",
    "    features = tfidf.transform(df['keluhan']).toarray()\n",
    "    return features\n",
    "\n",
    "def get_category_name(category_id):\n",
    "    for category, id_ in category_codes.items():    \n",
    "        if id_ == category_id:\n",
    "            return category\n",
    "\n",
    "def predict_from_text(text):\n",
    "    # Predict using the input model\n",
    "    ncc_prediction = ncc.predict(create_features(text))[0]\n",
    "    \n",
    "    # Return result\n",
    "    ncc_category = get_category_name(ncc_prediction)\n",
    "    \n",
    "    print(\"The predicted category using nearest centroid classifier model is %s.\" %(ncc_category))\n",
    "    # print(\"The conditional probability is: %a\" %(prediction_proba.max()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tender-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'saya mengalami kesulitan dalam membayar Eprt di m-banking mandiri, mohon bantuannya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radical-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using nearest centroid classifier model is Pusat Bahasa.\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
