{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "static-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hired-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessing:\n",
    "    def __init__(self, text=\"test\"):\n",
    "        self.text = text\n",
    "\n",
    "    def lowercase(self):\n",
    "        \"\"\"Convert to lowercase\"\"\"\n",
    "        self.text = str(self.text).lower()\n",
    "        self.text = self.text.strip()\n",
    "        return self\n",
    "\n",
    "    def remove_url(self):\n",
    "        \"\"\"Remove URL (http/https/www)\"\"\"\n",
    "        self.text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_email(self):\n",
    "        \"\"\"Remove email\"\"\"\n",
    "        self.text = re.sub(\"\\S*@\\S*\\s?\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_between_square_brackets(self):\n",
    "        \"\"\"Remove string diantara square brackets []\"\"\"\n",
    "        self.text = re.sub(\"\\[[^]]*\\]\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        \"\"\"Remove angka\"\"\"\n",
    "        self.text = re.sub(\"[-+]?[0-9]+\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_emoji(self):\n",
    "        \"\"\"Remove emoji \"\"\"\n",
    "        emoji_pattern = re.compile(\n",
    "            \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            \"]+\",\n",
    "            flags=re.UNICODE,\n",
    "        )\n",
    "        self.text = emoji_pattern.sub(r\"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_emoticon(self):\n",
    "        \"\"\"Remove emoticon\"\"\"\n",
    "        emoticon_pattern = re.compile(u\"(\" + u\"|\".join(k for k in EMOTICONS) + u\")\")\n",
    "        self.text = emoticon_pattern.sub(r\"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        \"\"\"Remove tanda baca\"\"\"\n",
    "        self.text = re.sub(r\"[^\\w\\s]\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def normalize_word(self):\n",
    "        \"\"\"Normalize slang word\"\"\"\n",
    "        normal_word_path = pd.read_csv(\"C:/Users/ASUS/TA01/00_data/key_norm.csv\")\n",
    "\n",
    "        self.text = \" \".join(\n",
    "            [\n",
    "                normal_word_path[normal_word_path[\"singkat\"] == word][\"hasil\"].values[0]\n",
    "                if (normal_word_path[\"singkat\"] == word).any()\n",
    "                else word\n",
    "                for word in self.text.split()\n",
    "            ]\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def stemming(self):\n",
    "        \"\"\"Stemming menggunakan Sastrawi\"\"\"\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        self.text = stemmer.stem(self.text)\n",
    "        return self\n",
    "\n",
    "    def tokenize(self):\n",
    "        \"\"\"Tokenize words\"\"\"\n",
    "        self.words = nltk.word_tokenize(self.text)\n",
    "        return self\n",
    "\n",
    "    def stopwords_removal(self):\n",
    "        \"\"\"Stopword removal\"\"\"\n",
    "        stopword = stopwords.words(\"indonesian\")\n",
    "        more_stopword = [\n",
    "            \"assalamualaikum\", \"wr\", \"wb\", \"pak\",\n",
    "            \"bu\", \"selamat\", \"siang\", \"pagi\",\n",
    "            \"sore\", \"malam\", \"saya\",\n",
    "            \"terimakasih\", \"terima\",\n",
    "            \"kasih\", \"kepada\", \"bpk\",\n",
    "            \"ibu\", \"mohon\", \"tolong\",\n",
    "            \"maaf\", \"dear\", \"wassalamualaikum\",\n",
    "            \"regards\", \"nbsp\", \"amp\", \"lg\", \"lgi\", \"kak\",\n",
    "            \"bapakibu\",\"bapak\", \"admin\", \"pakbu\", \"bupak\",\n",
    "            \"wrwb\", \"ya\", \"min\", \"nim\", \"jurus\" ]  # tambah stopword\n",
    "        stop_factory = stopword + more_stopword\n",
    "        stop_factory.remove('tak')\n",
    "        stop_factory.remove('akhir')\n",
    "        \n",
    "        clean_words = []\n",
    "        for word in self.words:\n",
    "            if word not in stop_factory:\n",
    "                clean_words.append(word)\n",
    "        self.words = clean_words  \n",
    "        return self\n",
    "\n",
    "    def join_words(self):\n",
    "        \"\"\"Menggabungkan kata hasil tokenize\"\"\"\n",
    "        self.words = \" \".join(self.words)\n",
    "        return self\n",
    "    \n",
    "    def do_all(self, text):\n",
    "        \"\"\"Do all text preprocessing process\"\"\" \n",
    "        self.text = text\n",
    "        self = self.lowercase()\n",
    "        self = self.remove_url()\n",
    "        self = self.remove_email()\n",
    "        self = self.remove_between_square_brackets()\n",
    "        self = self.remove_numbers()\n",
    "        self = self.remove_emoticon()\n",
    "        self = self.remove_emoji()\n",
    "        self = self.remove_punctuation()\n",
    "        self = self.normalize_word()\n",
    "        self = self.stemming()\n",
    "        self = self.tokenize()\n",
    "        self = self.stopwords_removal()\n",
    "        self = self.join_words()\n",
    "        return self.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lesser-balloon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keluhan</th>\n",
       "      <th>bagian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Pembayaran SPP Genap 1415 dianggap belum lu...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selamat sore.\\n Saya Andika mahasiswa sistem i...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohon maaf saya haidar mau komplain pada saat ...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assalamualaikum pak/bu, permisi saya\\n ABBAS P...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Halo saya mau tanya, tadi saya ke BNI untuk ba...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>bagaimana cara masuk igracias ketika saya lupa...</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>mohon untuk mempermudah untuk melakukan keluha...</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>saya tidak bisa memasukin akun igracias padaha...</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>tolong igracias diperbarui lagi dong tampilannya</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>Assalamualaikum wr. wb.\\nSelamat pagi. Nama sa...</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                keluhan  \\\n",
       "0     1. Pembayaran SPP Genap 1415 dianggap belum lu...   \n",
       "1     Selamat sore.\\n Saya Andika mahasiswa sistem i...   \n",
       "2     Mohon maaf saya haidar mau komplain pada saat ...   \n",
       "3     Assalamualaikum pak/bu, permisi saya\\n ABBAS P...   \n",
       "4     Halo saya mau tanya, tadi saya ke BNI untuk ba...   \n",
       "...                                                 ...   \n",
       "1548  bagaimana cara masuk igracias ketika saya lupa...   \n",
       "1549  mohon untuk mempermudah untuk melakukan keluha...   \n",
       "1550  saya tidak bisa memasukin akun igracias padaha...   \n",
       "1551   tolong igracias diperbarui lagi dong tampilannya   \n",
       "1552  Assalamualaikum wr. wb.\\nSelamat pagi. Nama sa...   \n",
       "\n",
       "                                     bagian  \n",
       "0                                 AKUNTANSI  \n",
       "1                                 AKUNTANSI  \n",
       "2                                 AKUNTANSI  \n",
       "3                                 AKUNTANSI  \n",
       "4                                 AKUNTANSI  \n",
       "...                                     ...  \n",
       "1548  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1549  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1550  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1551  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1552  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "\n",
       "[1553 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/ASUS/TA01/01_data_analysis/01_pickle/01_data_training.pickle'\n",
    "\n",
    "with open(data_path, 'rb') as data_training:\n",
    "    data = pickle.load(data_training)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "descending-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextPreprocessing() # load module text preprocessing\n",
    "\n",
    "data['clean_keluhan'] = data['keluhan'].apply(tp.do_all) #apply text preprocessing\n",
    "\n",
    "data.to_csv('C:/Users/ASUS/TA01/00_data/clean_data_training.csv', encoding='utf-8') #simpan dataset bersih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "tp = TextPreprocessing() # load module text preprocessing\n",
    "\n",
    "def dask_this(data):\n",
    "    data['clean_keluhan'] = data['keluhan'].apply(tp.do_all)\n",
    "    return data\n",
    "\n",
    "ddata = dd.from_pandas(data, npartitions=10)\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    data = ddata.map_partitions(dask_this).compute(scheduler='processes', num_workers=10)\n",
    "except:\n",
    "    print('Text preprocessing failed !')\n",
    "else:\n",
    "    data.to_csv('C:/Users/ASUS/TA01/00_data/clean_data_training.csv', encoding='utf-8')\n",
    "    print('Text preprocessing success !')\n",
    "    print('Elapsed time:', time.time() - start_time, 'seconds')\n",
    "finally:\n",
    "    print('\\nFinish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "conventional-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_keluhan</th>\n",
       "      <th>bagian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayar spp genap anggap lunas igracias bayar ta...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andika mahasiswa sistem informasi akuntansi an...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haidar komplain bayar bank bni bank milik tera...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permisi abbas pahlawan nazarsyah kelas tt laku...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>halo bni bayar semester tellernya nominal baya...</td>\n",
       "      <td>AKUNTANSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>masuk igracias lupa password akun</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>mudah laku keluh masuk igracias</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>memasukin akun igracias akun</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>igracias tampil</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>nama muhammad hariz kait sign in sesuai akun s...</td>\n",
       "      <td>RISET DAN LAYANAN TEKNOLOGI INFORMASI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_keluhan  \\\n",
       "0     bayar spp genap anggap lunas igracias bayar ta...   \n",
       "1     andika mahasiswa sistem informasi akuntansi an...   \n",
       "2     haidar komplain bayar bank bni bank milik tera...   \n",
       "3     permisi abbas pahlawan nazarsyah kelas tt laku...   \n",
       "4     halo bni bayar semester tellernya nominal baya...   \n",
       "...                                                 ...   \n",
       "1548                  masuk igracias lupa password akun   \n",
       "1549                    mudah laku keluh masuk igracias   \n",
       "1550                       memasukin akun igracias akun   \n",
       "1551                                    igracias tampil   \n",
       "1552  nama muhammad hariz kait sign in sesuai akun s...   \n",
       "\n",
       "                                     bagian  \n",
       "0                                 AKUNTANSI  \n",
       "1                                 AKUNTANSI  \n",
       "2                                 AKUNTANSI  \n",
       "3                                 AKUNTANSI  \n",
       "4                                 AKUNTANSI  \n",
       "...                                     ...  \n",
       "1548  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1549  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1550  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1551  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "1552  RISET DAN LAYANAN TEKNOLOGI INFORMASI  \n",
       "\n",
       "[1553 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['clean_keluhan', 'bagian']\n",
    "data = data[columns]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incomplete-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('02_pickle/02_clean_data.pickle', 'wb') as output:\n",
    "    pickle.dump(data, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
